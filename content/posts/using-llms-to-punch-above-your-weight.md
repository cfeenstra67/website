---
title: 'Using LLMs to Punch Above your Weight!'
subtitle: Talk from the LLMs in Production Conference, April 2023
date: '2022-06-11'
description: In April 2023 I gave this talk at the LLMs in Production Conference. I talk about how Anzen has used large language models to help us rapidly build high-quality ML-powered features to solve difficult problems we've come across at a very low cost relative to training models from scratch.
---
In April 2023 I was honored to be able to speak at the [LLMs in Production](https://home.mlops.community/public/events/llms-in-production-conference-2023-04-13) virtual conference put on by the MLOps Community. You can find the talk below:

<div class="flex flex-col items-center">
    <iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/1_NTxx3CJXg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
</div>

In the talk I go through a couple of use-cases at [Anzen](https://www.anzen.com) where we've made use of large language models to solve for our business needs. Anzen is still a very small company and we're quite constrainted on engineering resources, so I focus on how large language models have allowed us to bootstrap these features with a very small amount of time and data to work with. Compared to just a few years ago when implementing an ML-powered feature often meant training your own model from scratch or something close to it, fine-tuning and off-the-shelf products built on LLMs can allow businesses to implement these features almost as quickly as any other software feature.
