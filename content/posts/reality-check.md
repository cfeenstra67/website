---
title: 'Reality Check: Overcoming the Hallucination Hurdle in Generative AI'
subtitle: Talk from LLMs and the Generative AI Revolution, September 2023
date: '2023-09-16'
description: In September 2023 I gave this talk at the "LLMs and the Generative AI Revolution" virual conference put on by the AI Infrastructure Alliance. I talk about how to build reliable software on top of LLMs despite their propensity to hallucinate.
---

In September 2023 I spoke at the [LLMs and the Generative AI Revolution](https://community.ai-infrastructure.org/public/events/llms-and-the-generative-ai-revolution-2023-09-14) virtual conference. You can find the talk below:

<div class="flex flex-col items-center">
    <iframe width="560" height="315" src="https://www.youtube.com/embed/CJKth2WROVY?si=GgN3o4MALGmTBX61" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
</div>

I discuss the topic of building reliable applications in domains where correctness matters on top of LLMs. I start by talking through techniques for working with the LLMs themselves, and also spend some time on talking about how to architect applications around the unreliability LLMs to ensure the software continues to maintain quality over time and can be improved with more usage. 
